{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5635fbca-6bf1-4c83-9003-f18951d4982b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Lectura de la tabla Bronze\n",
    "# ============================================================\n",
    "# Usamos spark.read.table para cargar la tabla Delta previamente creada\n",
    "# en la capa Bronze. Esta tabla contiene los datos crudos consolidados\n",
    "# de todas las sucursales, junto con columnas de auditoría como\n",
    "# 'archivo_fuente' y 'fecha_ingesta'.\n",
    "\n",
    "df_TechMart_SilverStage = spark.read.table(\"workspace.default.df_techmart_broze_ingestion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "757e3c32-3f82-4eb0-8871-199c28b490d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Transformaciones sobre la tabla SilverStage\n",
    "# ============================================================\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "df_TechMart_SilverStage = (\n",
    "    df_TechMart_SilverStage\n",
    "    # 1. Convertir la columna 'fecha' a tipo timestamp\n",
    "    #    Se especifica el formato 'yyyy-MM-dd HH:mm:ss' para asegurar\n",
    "    #    que Spark interprete correctamente la fecha y hora.\n",
    "    .withColumn(\n",
    "        \"fecha\",\n",
    "        F.to_timestamp(\"fecha\", \"yyyy-MM-dd HH:mm:ss\")\n",
    "    )\n",
    "    # 2. Eliminar la columna 'fecha'\n",
    "    #    Aquí se elimina la columna recién creada, lo cual normalmente\n",
    "    #    no tendría sentido porque acabamos de transformarla.\n",
    "    #    (Probablemente se buscaba limpiar duplicados o redefinir la columna).\n",
    "    .drop(\"fecha\")\n",
    "    # 3. Renombrar la columna 'fecha_ingesta' como 'fecha'\n",
    "    #    Esto reemplaza la columna de ingesta por el nombre genérico 'fecha',\n",
    "    #    dejando como referencia la fecha de carga en lugar de la fecha original.\n",
    "    .withColumnRenamed(\"fecha_ingesta\", \"fecha\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0129e62e-4346-4cf2-9850-df2e3d32ca91",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Derivación de atributos de fecha en la capa SilverStage\n",
    "# ============================================================\n",
    "\n",
    "df_TechMart_SilverStage = (\n",
    "    df_TechMart_SilverStage\n",
    "    # 1. Extraer el año desde la columna 'fecha'\n",
    "    .withColumn(\"año\", F.year(\"fecha\"))\n",
    "    # 2. Extraer el mes (valor numérico 1–12)\n",
    "    .withColumn(\"mes\", F.month(\"fecha\"))\n",
    "    # 3. Extraer el día del mes (1–31)\n",
    "    .withColumn(\"dia\", F.dayofmonth(\"fecha\"))\n",
    "    # 4. Obtener el nombre completo del día de la semana (ej. Monday, Tuesday)\n",
    "    .withColumn(\"dia_semana\", F.date_format(\"fecha\", \"EEEE\"))\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab769cad-a624-41d5-a33b-9eedf588a436",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Normalización de texto en la capa SilverStage\n",
    "# ============================================================\n",
    "\n",
    "df_TechMart_SilverStage = (\n",
    "    df_TechMart_SilverStage\n",
    "    # 1. Convertir la columna 'sucursal' a mayúsculas\n",
    "    #    Esto asegura consistencia en los nombres de sucursal,\n",
    "    #    evitando problemas de comparación por diferencias de formato.\n",
    "    .withColumn(\"sucursal\", F.upper(F.col(\"sucursal\")))\n",
    "    \n",
    "    # 2. Convertir la columna 'producto' a minúsculas\n",
    "    #    Se estandariza el nombre de los productos para facilitar\n",
    "    #    búsquedas, agrupaciones y evitar duplicados por diferencias\n",
    "    #    de capitalización (ej. \"Laptop\" vs \"laptop\").\n",
    "    .withColumn(\"producto\", F.lower(F.col(\"producto\")))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63018e09-e70d-4eae-95ce-d88a1471dad5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Eliminación de duplicados en la capa SilverStage\n",
    "# ============================================================\n",
    "\n",
    "# Usamos dropDuplicates indicando la columna 'id_venta' como clave única.\n",
    "# Esto asegura que, si existen múltiples registros con el mismo id_venta,\n",
    "# solo se conserve uno y se eliminen los duplicados.\n",
    "# Es una práctica común en la capa Silver para garantizar\n",
    "# la integridad y consistencia de los datos antes de pasar a la capa Gold.\n",
    "\n",
    "df_TechMart_SilverStage = df_TechMart_SilverStage.dropDuplicates([\"id_venta\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f1b8f9e-4547-48ac-8065-1c67b27f2d82",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Filtrado de registros inválidos en la capa SilverStage\n",
    "# ============================================================\n",
    "\n",
    "# Usamos filter para conservar únicamente las filas donde la columna 'total' > 0.\n",
    "# Esto elimina registros con valores nulos, cero o negativos en el campo 'total',\n",
    "# garantizando que solo se mantengan ventas válidas en el DataFrame SilverStage.\n",
    "\n",
    "df_TechMart_SilverStage = df_TechMart_SilverStage.filter(F.col(\"total\") > 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f550030-b9e3-45d0-99eb-b67ed7e61d33",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Validación de campos obligatorios en la capa SilverStage\n",
    "# ============================================================\n",
    "\n",
    "# Definimos una lista con los nombres de los campos que deben ser obligatorios.\n",
    "# Estos campos no pueden contener valores nulos, ya que son críticos para el análisis:\n",
    "# - id_venta   → identificador único de la transacción\n",
    "# - fecha      → fecha de la venta\n",
    "# - sucursal   → sucursal donde ocurrió la venta\n",
    "# - producto   → producto vendido\n",
    "# - total      → monto total de la transacción\n",
    "\n",
    "campos_obligatorios = [\"id_venta\", \"fecha\", \"sucursal\", \"producto\", \"total\"]\n",
    "\n",
    "# Iteramos sobre cada campo obligatorio y aplicamos un filtro\n",
    "# para eliminar las filas donde ese campo sea nulo.\n",
    "# De esta forma, garantizamos que el DataFrame SilverStage\n",
    "# solo contenga registros válidos y completos.\n",
    "for campo in campos_obligatorios:\n",
    "    df_TechMart_SilverStage = df_TechMart_SilverStage.filter(F.col(campo).isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1105823-8914-4ab4-965e-afcb618a73e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Escritura de la tabla Silver particionada\n",
    "# ============================================================\n",
    "\n",
    "# Guardamos el DataFrame SilverStage en formato Delta Lake.\n",
    "# Se utiliza 'append' para permitir cargas incrementales sin sobrescribir datos previos.\n",
    "# La partición se realiza por la columna 'mes', lo que optimiza las consultas\n",
    "# que filtran o agrupan por mes, ya que Spark puede leer solo las particiones necesarias.\n",
    "# Finalmente, se registra la tabla en el catálogo con el nombre 'df_techmart_silver_partitioned'.\n",
    "\n",
    "df_TechMart_SilverStage.write.format(\"delta\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .partitionBy(\"mes\") \\\n",
    "    .saveAsTable(\"df_techmart_silver_partitioned\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02_silver_transformation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}